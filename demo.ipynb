{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Gymnasium\n",
    "import gymnasium as gym\n",
    "\n",
    "# Sinergym\n",
    "import sinergym\n",
    "from sinergym.utils.rewards import ExpReward\n",
    "from src.sinergym_wrapper import SinergymWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the EnergyPlus path to the system path\n",
    "sys.path.append('./EnergyPlus-23-1-0')\n",
    "# Set the EnergyPlus path as an environment variable\n",
    "os.environ['EPLUS_PATH'] = './EnergyPlus-23-1-0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment ID\n",
    "id = \"Eplus-5zone-hot-continuous-stochastic-v1\"\n",
    "\n",
    "# Weather\n",
    "weather_files = ['USA_AZ_Davis-Monthan.AFB.722745_TMY3.epw']\n",
    "\n",
    "# mu, sigma and theta for the weather variability\n",
    "# In the original version, weather_variability was a triple (mu, sigma, theta)\n",
    "# that only affected the drybulb (outdoor temperature), while now it is a dictionary\n",
    "# with the mean, sigma and theta for each weather variable we want to vary\n",
    "# NOTE: Check apply_weather_variability method in CustomModelJSON class\n",
    "weather_variability = {\n",
    "    'drybulb': np.array([5.53173187e+00, 0.00000000e+00, 2.55034944e-03]), \n",
    "    'relhum': np.array([1.73128872e+01, 0.00000000e+00, 2.31712760e-03]), \n",
    "    'winddir': np.array([7.39984654e+01, 0.00000000e+00, 4.02298013e-04]), \n",
    "    'dirnorrad': np.array([3.39506556e+02, 0.00000000e+00, 9.78192172e-04]), \n",
    "    'windspd': np.array([1.64655725e+00, 0.00000000e+00, 3.45045547e-04])}\n",
    "\n",
    "# Reward function and kwargs\n",
    "reward = ExpReward\n",
    "reward_kwargs = {\n",
    "    'temperature_variables': ['air_temperature'],\n",
    "    'energy_variables': ['HVAC_electricity_demand_rate'],\n",
    "    'range_comfort_winter': [20, 23],\n",
    "    'range_comfort_summer': [23, 26],\n",
    "    'energy_weight': 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#==============================================================================================#\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Creating Gymnasium environment... [5zone-hot-continuous-stochastic-v1]\u001b[0m\n",
      "#==============================================================================================#\n",
      "\u001b[38;20m[MODELING] (INFO) : Experiment working directory created [/home/luigi/Documents/SmartEnergyOptimizationRL/Eplus-env-5zone-hot-continuous-stochastic-v1-res1]\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Model Config is correct.\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Updated building model with whole Output:Variable available names\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Updated building model with whole Output:Meter available names\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : runperiod established: {'start_day': 1, 'start_month': 1, 'start_year': 1991, 'end_day': 31, 'end_month': 12, 'end_year': 1991, 'start_weekday': 0, 'n_steps_per_hour': 4}\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Episode length (seconds): 31536000.0\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : timestep size (seconds): 900.0\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : timesteps per episode: 35040\u001b[0m\n",
      "\u001b[38;20m[REWARD] (INFO) : Reward function initialized.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment 5zone-hot-continuous-stochastic-v1 created successfully.\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Experiment working directory created [/home/luigi/Documents/SmartEnergyOptimizationRL/Eplus-env-eplus-env-v1-res1]\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Model Config is correct.\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Updated building model with whole Output:Variable available names\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Updated building model with whole Output:Meter available names\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : runperiod established: {'start_day': 1, 'start_month': 1, 'start_year': 1991, 'end_day': 31, 'end_month': 12, 'end_year': 1991, 'start_weekday': 0, 'n_steps_per_hour': 4}\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Episode length (seconds): 31536000.0\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : timestep size (seconds): 900.0\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : timesteps per episode: 35040\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Create the environment\n",
    "env = gym.make(\n",
    "    id=id,\n",
    "    weather_files=weather_files,\n",
    "    reward=reward,\n",
    "    reward_kwargs=reward_kwargs,\n",
    "    weather_variability=weather_variability\n",
    ")\n",
    "\n",
    "# Wrap the environment (to account for the different weather variability)\n",
    "env =  SinergymWrapper(env)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    #==================================================================================#\n",
      "                                ENVIRONMENT NAME: 5zone-hot-continuous-stochastic-v1\n",
      "    #==================================================================================#\n",
      "    #----------------------------------------------------------------------------------#\n",
      "                                ENVIRONMENT INFO:\n",
      "    #----------------------------------------------------------------------------------#\n",
      "    - Building file: /home/luigi/Documents/SmartEnergyOptimizationRL/.venv/lib/python3.10/site-packages/sinergym/data/buildings/5ZoneAutoDXVAV.epJSON\n",
      "    - Zone names: ['PLENUM-1', 'SPACE1-1', 'SPACE2-1', 'SPACE3-1', 'SPACE4-1', 'SPACE5-1']\n",
      "    - Weather file(s): ['USA_AZ_Davis-Monthan.AFB.722745_TMY3.epw']\n",
      "    - Current weather used: /home/luigi/Documents/SmartEnergyOptimizationRL/.venv/lib/python3.10/site-packages/sinergym/data/weather/USA_AZ_Davis-Monthan.AFB.722745_TMY3.epw\n",
      "    - Episodes executed: 0\n",
      "    - Workspace directory: /home/luigi/Documents/SmartEnergyOptimizationRL/Eplus-env-eplus-env-v1-res1\n",
      "    - Reward function: <sinergym.utils.rewards.ExpReward object at 0x7f2b0acac1c0>\n",
      "    - Reset default options: {'weather_variability': {'drybulb': array([5.53173187e+00, 0.00000000e+00, 2.55034944e-03]), 'relhum': array([1.73128872e+01, 0.00000000e+00, 2.31712760e-03]), 'winddir': array([7.39984654e+01, 0.00000000e+00, 4.02298013e-04]), 'dirnorrad': array([3.39506556e+02, 0.00000000e+00, 9.78192172e-04]), 'windspd': array([1.64655725e+00, 0.00000000e+00, 3.45045547e-04])}}\n",
      "    - Run period: {'start_day': 1, 'start_month': 1, 'start_year': 1991, 'end_day': 31, 'end_month': 12, 'end_year': 1991, 'start_weekday': 0, 'n_steps_per_hour': 4}\n",
      "    - Episode length: 31536000.0\n",
      "    - Number of timesteps in an episode: 35040\n",
      "    - Timestep size (seconds): 900.0\n",
      "    - It is discrete?: False\n",
      "    #----------------------------------------------------------------------------------#\n",
      "                                ENVIRONMENT SPACE:\n",
      "    #----------------------------------------------------------------------------------#\n",
      "    - Observation space: Box(-50000000.0, 50000000.0, (17,), float32)\n",
      "    - Observation variables: ['month', 'day_of_month', 'hour', 'outdoor_temperature', 'outdoor_humidity', 'wind_speed', 'wind_direction', 'diffuse_solar_radiation', 'direct_solar_radiation', 'htg_setpoint', 'clg_setpoint', 'air_temperature', 'air_humidity', 'people_occupant', 'co2_emission', 'HVAC_electricity_demand_rate', 'total_electricity_HVAC']\n",
      "    - Action space: Box([12.  23.5], [21.5 40. ], (2,), float32)\n",
      "    - Action variables: ['Heating_Setpoint_RL', 'Cooling_Setpoint_RL']\n",
      "    #==================================================================================#\n",
      "                                    SIMULATOR\n",
      "    #==================================================================================#\n",
      "    *NOTE: To have information about available handlers and controlled elements, it is\n",
      "    required to do env reset before to print information.*\n",
      "\n",
      "    Is running? : False\n",
      "    #----------------------------------------------------------------------------------#\n",
      "                                AVAILABLE ELEMENTS:\n",
      "    #----------------------------------------------------------------------------------#\n",
      "    *Some variables can not be here depending if it is defined Output:Variable field\n",
      "     in building model. See documentation for more information.*\n",
      "\n",
      "    None\n",
      "    #----------------------------------------------------------------------------------#\n",
      "                                CONTROLLED ELEMENTS:\n",
      "    #----------------------------------------------------------------------------------#\n",
      "    - Actuators: None\n",
      "    - Variables: None\n",
      "    - Meters: None\n",
      "    - Internal Variables: None\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "env.unwrapped.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Starting a new episode... [5zone-hot-continuous-stochastic-v1] [Episode 1]\u001b[0m\n",
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[MODELING] (INFO) : Episode directory created [/home/luigi/Documents/SmartEnergyOptimizationRL/Eplus-env-eplus-env-v1-res1/Eplus-env-sub_run1]\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Weather file USA_AZ_Davis-Monthan.AFB.722745_TMY3.epw used.\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Adapting weather to building model. [USA_AZ_Davis-Monthan.AFB.722745_TMY3.epw]\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Saving episode output path... [/home/luigi/Documents/SmartEnergyOptimizationRL/Eplus-env-eplus-env-v1-res1/Eplus-env-sub_run1/output]\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : Running EnergyPlus with args: ['-w', '/home/luigi/Documents/SmartEnergyOptimizationRL/Eplus-env-eplus-env-v1-res1/Eplus-env-sub_run1/USA_AZ_Davis-Monthan.AFB.722745_TMY3_Randomized.epw', '-d', '/home/luigi/Documents/SmartEnergyOptimizationRL/Eplus-env-eplus-env-v1-res1/Eplus-env-sub_run1/output', '/home/luigi/Documents/SmartEnergyOptimizationRL/Eplus-env-eplus-env-v1-res1/Eplus-env-sub_run1/5ZoneAutoDXVAV.epJSON']\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 1 started.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers initialized.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers are ready.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : System is ready.\u001b[0m\n",
      "\n",
      "\n",
      "OBSERVATION:  [1.0000000e+00 1.0000000e+00 0.0000000e+00 9.0797100e+00 5.8616100e+01\n",
      " 3.9327860e+00 1.2714914e+02 0.0000000e+00 0.0000000e+00 1.4517688e+01\n",
      " 3.1385578e+01 1.9513937e+01 4.2447315e+01 0.0000000e+00 0.0000000e+00\n",
      " 4.7434094e+02 4.2690684e+05]\n",
      "REWARD:  -48.89740559615044\n",
      "TERMINATED:  False\n",
      "TRUNCATED:  False\n",
      "INFO:  {'time_elapsed(hours)': 0.5, 'month': 1, 'day': 1, 'hour': 0, 'is_raining': False, 'action': array([14.517688, 31.385578], dtype=float32), 'timestep': 2, 'reward': -48.89740559615044, 'energy_term': -47.434092869631144, 'comfort_term': -1.4633127265192982, 'reward_weight': 0.1, 'abs_energy': 474.3409286963114, 'abs_comfort': 1.625903029465887, 'energy_values': [474.3409286963114], 'temp_values': [19.51393662812762]}\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    obs, info = env.reset()\n",
    "    rewards = []\n",
    "    terminated = False\n",
    "    current_month = 0\n",
    "    while not terminated:\n",
    "        a = env.action_space.sample()\n",
    "        obs, reward, terminated, truncated, info = env.step(a)\n",
    "        if info['month'] != current_month:  # display results every month\n",
    "            current_month = info['month']\n",
    "            print(\"\\n\\nOBSERVATION: \", obs)\n",
    "            print(\"REWARD: \", reward)\n",
    "            print(\"TERMINATED: \", terminated)\n",
    "            print(\"TRUNCATED: \", truncated)\n",
    "            print(\"INFO: \", info)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 18:24:55.437214: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-06 18:24:55.467703: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-06 18:24:55.467729: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-06 18:24:55.468654: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-06 18:24:55.474625: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-06 18:24:56.092949: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Starting a new episode... [5zone-hot-continuous-stochastic-v1] [Episode 2]\u001b[0m\n",
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[MODELING] (INFO) : Episode directory created [/home/luigi/Documents/SmartEnergyOptimizationRL/Eplus-env-eplus-env-v1-res1/Eplus-env-sub_run2]\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Weather file USA_AZ_Davis-Monthan.AFB.722745_TMY3.epw used.\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Adapting weather to building model. [USA_AZ_Davis-Monthan.AFB.722745_TMY3.epw]\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Saving episode output path... [/home/luigi/Documents/SmartEnergyOptimizationRL/Eplus-env-eplus-env-v1-res1/Eplus-env-sub_run2/output]\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : Running EnergyPlus with args: ['-w', '/home/luigi/Documents/SmartEnergyOptimizationRL/Eplus-env-eplus-env-v1-res1/Eplus-env-sub_run2/USA_AZ_Davis-Monthan.AFB.722745_TMY3_Randomized.epw', '-d', '/home/luigi/Documents/SmartEnergyOptimizationRL/Eplus-env-eplus-env-v1-res1/Eplus-env-sub_run2/output', '/home/luigi/Documents/SmartEnergyOptimizationRL/Eplus-env-eplus-env-v1-res1/Eplus-env-sub_run2/5ZoneAutoDXVAV.epJSON']\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 2 started.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers are ready.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : System is ready.\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------| 6%\n",
      "| time/              |      |\n",
      "|    fps             | 424  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 4    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "--------------------------------------------------------------------------------------------------------------| 12%\n",
      "| time/                   |              |\n",
      "|    fps                  | 572          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030761333 |\n",
      "|    clip_fraction        | 0.00249      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.31e+07     |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.000621    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 2.21e+07     |\n",
      "------------------------------------------\n",
      "--------------------------------------------------------------------------------------------------------------| 18%\n",
      "| time/                   |              |\n",
      "|    fps                  | 670          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018937367 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.18e+06     |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.000239    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 1.58e+07     |\n",
      "------------------------------------------\n",
      "--------------------------------------------------------------------------------------------------------------| 23%\n",
      "| time/                   |              |\n",
      "|    fps                  | 740          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063194325 |\n",
      "|    clip_fraction        | 0.0401       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.85        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.3e+06      |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00386     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 9.73e+06     |\n",
      "------------------------------------------\n",
      "--------------------------------------------------------------------------------------------------------------| 29%\n",
      "| time/                   |              |\n",
      "|    fps                  | 786          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032574167 |\n",
      "|    clip_fraction        | 0.00366      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.98e+06     |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00112     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 1.54e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |***************************************************************************************************| 99%\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "# Create the PPO agent\n",
    "model = PPO('MlpPolicy', env, verbose=1)\n",
    "\n",
    "# Train the agent\n",
    "model.learn(total_timesteps=10000)\n",
    "\n",
    "# Save the agent\n",
    "model.save(\"ppo_agent\")\n",
    "\n",
    "# To load the trained agent\n",
    "# model = PPO.load(\"ppo_agent\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |***************************************************************************************************| 99%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment closed. [5zone-hot-continuous-stochastic-v1]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
